# -*- coding: utf-8 -*-
"""deep_clasification_label_predict_990207.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13DfnMMyDkyrwOX5I6oEzVpmyZRvR7Uls
"""

import pandas as pd
import re
IN_PATH = "all-chat-clean.xlsx"

df = pd.ExcelFile(IN_PATH)
df1 = df.parse("Sheet1",encoding="utf-8")
print(df1)

#delet [20:3:4]
chatId = []
values = []
for rownum in range(len(df1)):
    chatid = df1.iat[rownum,0]
    row = df1.iat[rownum, 1]
    for x in row.split('|'):
        if re.match(r"[^|0-9|]\D+", x):
            chatId.append(chatid)
            values.append(x)
data = pd.DataFrame()
data['chatid'] = chatId
data['value'] = values
print(data)

#delet name support

data=data[~data['value'].str.contains('support')]
data=data[~data['value'].str.contains('salimi')]
data=data[~data['value'].str.contains('ایرانژاد')]
data=data[~data['value'].str.contains(' سهند مددی')]
data=data[~data['value'].str.contains('صالح')]
data=data[~data['value'].str.contains('رضایی')]
data=data[~data['value'].str.contains('ابوطالبی')]
data=data[~data['value'].str.contains('محمدی')]
data=data[~data['value'].str.contains('شعبانی')]
data=data[~data['value'].str.contains('شایسته')]
data=data[~data['value'].str.contains('کبیری')]
data=data[~data['value'].str.contains('مقدم')]
data=data[~data['value'].str.contains(' دست ورز ')]
data=data[~data['value'].str.contains('محمدزاده')]

# tarkibe same chatid
new_data=data.groupby('chatid').agg({'value': lambda x:' ,'.join(x)})
print(new_data)
#save 
new_data.to_excel('test_for_LSTM.xlsx')

import tensorflow as tf
from keras.layers import Bidirectional, GlobalMaxPool1D, MaxPooling1D, Convolution1D,GRU
from keras.layers import Dense, Input, LSTM, Embedding, Dropout
from keras.layers import CuDNNLSTM
from keras.models import Sequential
from keras.layers import Flatten
from keras.layers.convolutional import Conv1D
from keras.models import Model
from keras import optimizers
from keras.layers import LSTM
from keras.applications import VGG16
from keras.utils.np_utils import to_categorical
from keras.metrics import categorical_accuracy
from keras.utils import plot_model
from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences
from gensim.models import KeyedVectors
from sklearn.preprocessing import LabelEncoder
import numpy as np
import pandas as pd
import xlrd
import codecs

train_data=xlrd.open_workbook('.xlsx')
train_data=pd.read_excel(train_data)
train_data.head()

test_data=xlrd.open_workbook('.xlsx')
test_data=pd.read_excel(test_data)
test_data.head()

category_y_train = train_data['label']
# category_y_test = test_data['label']
category_y_train

category_le = LabelEncoder()
y_train = category_le.fit_transform(train_data['label'])
print(y_train)

lstm_x_train = train_data['value'].values
# lstm_x_train = preprocess(lstm_x_train)
# test set
lstm_x_test = test_data['value'].values
# lstm_x_test = preprocess(lstm_x_test)

from keras.preprocessing.text import Tokenizer

tokenizer = Tokenizer(num_words=1000)
tokenizer.fit_on_texts(lstm_x_train)

X_train = tokenizer.texts_to_sequences(lstm_x_train)
X_test = tokenizer.texts_to_sequences(lstm_x_test)

vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index

print(lstm_x_train[2])
print(X_train[2])

from keras.preprocessing.sequence import pad_sequences
max_length = max([len(s.split()) for s in lstm_x_train])
X_train = pad_sequences(X_train, padding='post', maxlen=max_length)
X_test = pad_sequences(X_test, padding='post', maxlen=max_length)

# print(len(X_train[0, :]))
# print(X_train[0, :])
print(X_train.shape)
# print(len(X_test[0, :]))
# print(X_test[0, :])
print(X_test.shape)

y_train_classes = np.unique(y_train)
y_train_classes_len = len(y_train_classes)

# y_test_classes = np.unique(y_test)
# y_test_classes_len = len(y_test_classes)

from keras.utils import to_categorical
categorical_y_train = to_categorical(y_train, y_train_classes_len)

model = Sequential()
model.add(Embedding(vocab_size, 100, input_length=max_length))
model.add(Bidirectional(LSTM(50, return_sequences=True, name='lstm_layer')))
model.add(GlobalMaxPool1D())
model.add(Dropout(rate=0.5))
model.add(Dense(100, activation="relu"))
model.add(Dropout(rate=0.5))
model.add(Dense(y_train_classes_len, activation='softmax'))

model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=[categorical_accuracy])
model.summary()

batch_size =2
epochs = 50
hist = model.fit(X_train, categorical_y_train, batch_size=batch_size, epochs=epochs)

y_pred=model.predict_classes(X_test)
print(y_pred)

prediction=list(category_le.inverse_transform(y_pred))
print(prediction)

# test_data['prediction']=test_data.apply(prediction)
test_data['prediction']=prediction
print(test_data)
# test_data['label']=category_y
pred_data=test_data.drop(['chatid'],axis=1)
print(pred_data)

# test_data['prediction'].value_counts()